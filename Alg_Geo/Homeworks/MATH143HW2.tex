\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{quiver}
\usepackage{mathtools}
\usepackage{geometry}

\newgeometry{
    top=0.75in,
    bottom=0.75in,
    outer=0.75in,
    inner=0.75in
}

\title{Math 143 Homework 2}
\author{Aniruddh V.}
\date{September 2023}

\begin{document}

\maketitle

\section{Problem 1}
\textbf{a. } \textbf{Solution } Let $I, J \subset k[x_1, \ldots, x_n]$ be ideals, and $I + J \coloneqq \{f + g : f \in I, g \in J\}$. Let $P_1, P_2 \in I + J$.
Then, there are $f_1, f_2 \in I$ and $g_1, g_2 \in J$ such that $P_1 = f_1 + g_1$ and $P_2 = f_2 + g_2$. But this implies $P_1 + P_2 \in I+J$, because $P_1 + P_2 = (f_1 + f_2) + (g_1 + g_2)$,
with $f_1 + f_2 \in I$ and $g_1 + g_2 \in J$ since $I$ and $J$ are assumed to be ideals. 
Next, if $r \in  k[x_1, \ldots, x_n]$ and $P = f + g \in I + J$, then $rP \in I + J$, since $rP = r(f+g) = rf + rg$, with $rf \in I$ and $rj \in J$, since $I$ and $J$ are
assumed to be ideals. 
We have shown that if $P_1, P_2 \in I + J$, then $P_1 + P_2 \in I + J$ and if $r \in   k[x_1, \ldots, x_n]$, then $rP \in I + J$ for all $P \in I + J$. 
Thus $I + J$ is an ideal. $\square$ \\
\textbf{b. } \textbf{Solution } Suppose a point $P \in V(I) \cap V(J)$. Then for all $f \in I$ and $g \in J$, $f(P) = g(P) = 0$, so $f(P) + g(P) = 0$ as well. 
Thus $(f+g)(P) = 0$, so $V(I) \cap V(J) \subseteq V(I+J)$. Alternatively, suppose $P \in V(I + J)$. Then the polynomials $f+g \in I + J$ vanish at $P$. One way for this to happen is
if both $f$ and $g$ both vanish at $P$, that is $P \in V(I)$ and $P \in V(J)$. But then $P \in V(I) \cap V(J)$, so $V(I + J) \subseteq V(I) \cap V(J)$. 
But now we have  $V(I) \cap V(J) \subseteq V(I+J)$ and $V(I + J) \subseteq V(I) \cap V(J)$, so $V(I) \cap V(J) = V(I + J)$ $\square$

\section{Problem 2}
\textbf{a. } \textbf{Solution } The set $V(y - x^2) \subset \mathbb{A}^2$ is irreducible if and only if the ideal $\langle y - x^2 \rangle \subset \mathbb{C}^2$ is prime. 
An ideal $ R \subset I$ is prime if and only if the quotient $R / I$ is an integral domain. To this end, consider the ring homomorphism $\phi : k[x, y] \to k[x]$ which sends $f(x, y) \mapsto f(x, x^2)$
Clearly, $\phi$ is surjecrtive. We claim $\ker \phi = \langle y -x^2 \rangle$. Clearly $y - x^2 \in \ker \phi$, so $\langle y - x^2 \rangle \subset \ker \phi$. 
If $f \in \ker \phi$, then $f(x, x^2) = 0$, so $y - x^2$ divides $f$ and $\langle y - x^2 \rangle \supset \ker \phi$. Thus $\langle y - x^2 \rangle = \ker \phi$. Then, since $\phi$ is surjective,
by the first isomorphism theorem, $k[x, y] / \langle y - x^2 \rangle \cong k[x]$. $k[x]$ is an integral domain, since if $f(x)g(x) = 0$, then either $f(x) = 0$ or $g(x) = 0$, since $k$ is a field. 
Thus $k[x, y] / \langle y - x^2 \rangle$ is an integral domain, so $\langle y - x^2 \rangle$ is prime, and thus $V(y - x^2)$ is irreducible. \\
\textbf{b. } \textbf{Solution } Starting with $V(y^4 - x^2, y^4 - x^2y^2 + xy^2 -x^3)$, factoring each polynomial gives \\ $V \left(  (y^2-x)(y^2+x), (y^2+x)(y-x)(y+x)   \right)$. 
The $y^2 + x$ is common in both terms, and taking the points where $y^2 - x$, $y-x$, and $y+x$ vanish gives the set with two points $\{(1, 1), (1, -1)\}$. Then the decomposition becomes
$ V(y^4 - x^2, y^4 - x^2y^2 + xy^2 -x^3) = V(y^2 + x) \cup V((1, 1)) \cup V((1, -1)) $, where $V(y^2 + x)$ is irreducible by part \textbf{a}. 

\section{Problem 3}
\textbf{a. } \textbf{Solution } Let $I \subset R$ be an ideal, with $a^n, b^m \in I$. Then, by the binomial formula:
\[(a+b)^{n+m} = \sum_{k=1}^{n+m} {n+m \choose k} a^{n+m-k}b^k \] Expanding this gives
\[(a+b)^{n+m} = a^{n+m} + (n+m)a^{n+m-1}b + \cdots {+ n+m \choose m} a^n b^m + \cdots + (n+m)ab^{n+m-1} + b^{n+m} \] Factoring gives
\[(a+b)^{n+m} = a^n \underbrace{\left(a^m + \cdots + b^m\right)}_{r_1 \in R} + b^m \underbrace{\left({n+m \choose m+1}a^{n-1} b + \cdots + b^n \right)}_{r_2 \in R}\]
Since $I$ is an ideal, $r_1 a^n \in I$ and $r_2b^m \in I$, and thus $r_1 a^n + r_2 b^m = (a+b)^{n+m} \in I$ as well. \\
\textbf{b. } \textbf{Solution } Let $a, b \in \sqrt{I}$. Then, there are $n, m$ such that $a^n \in I$ and $b^m \in I$. By part \textbf{a}, $(a+b)^{n+m} \in I$ as well, and since there is $t$ such that
$(a+b)^t \in I$, $a+b \in \sqrt{I}$. Next, if $r \in R$ and $a \in \sqrt{I}$, there is some $n$ such that $(ra)^n = r^n a^n \in I$ since $I$ is an ideal, so $ra \in \sqrt{I}$. Thus $\sqrt{I}$ is an ideal. \\
\textbf{c. } \textbf{Solution } Suppose $f^r \in \sqrt{I}$. Then there exists $s$ such that $(f^r)^s \in I$. But $(f^r)^s = f^{rs}$, and since there is $n = rs$ such that $f^n \in I$, $f \in \sqrt{I}$. So $f^r \in \sqrt{I} \implies f \in \sqrt{I}$ and 
thus $\sqrt{I}$ is radical. \\
\textbf{d. } \textbf{Solution } Let $I \subset R$ be a prime ideal. Then if $ab \in I$, either $a \in I$ or $b \in I$. Now suppose $a^n \in I$. Since $a^n = a \cdot a \cdots a \cdot a$, $I$ being a prime ideal implies $a \in I$. Thus
$I$ is radical as well.

\section{Problem 4}
\textbf{a. } \textbf{Solution } Let $X, Y$ be algebraic sets, and let $p \in I(X \cup Y)$. Then $p$ vanishes on all of $X$ and $Y$, so certainly $p$ vanishes on $X$ and $Y$ individually.
This means $p \in I(X)$ and $p \in I(Y)$, so $p \in I(X) \cap I(Y)$ and $I(x \cup Y) \subseteq I(X) \cap I(Y)$. Now let $p \in I(X) \cap I(Y)$. Then $p$ vanishes on $X$ and $Y$, so $p$ vanishes
on $X \cup Y$ as well, and $p \in I(X \cup Y)$. Thus $I(X \cup Y) = I(X) \cap I(Y)$ \\
\textbf{b. } \textbf{Solution } This does not hold in general. Take $X = V(y)$, $Y = V(y + x^2)$. Then $I(X) + I(Y) = \langle y \rangle + \langle y + x^2 \rangle = \langle y, x^2 $.
But the intersection $X \cap Y$ contains only the origin, and thus $I(X \cap Y) = \langle y, x \rangle$. So in general $I(X \cap Y) \neq I(X) + I(Y)$

\section{Problem 5}
\textbf{Solution } Let $R$ be a ring such that every ascending chain of ideals $I_0 \subsetneq I_1 \subsetneq I_2 \subsetneq \cdots $ is finite. For the sake of contradiction, suppose $I$ is an ideal of $R$ that
is infinitely generated. Then there is an infinite set $G$ that generates $I$, that is $I = \langle G \rangle$. Suppose the elements in $G$ are $g_1, g_2, \ldots $. Then the ascending chain
of ideals $ \langle g_1 \rangle \subsetneq \langle g_1, g_2 \rangle \subsetneq \langle g_1, g_2, g_3 \rangle \subsetneq \cdots$ is an infinite ascending chain of ideals, contradicting the initial assumption 
that every ascending chain of ideals is finite. Thus, if $R$ is a ring in which every ascending chain of ideals is finite, then every ideal must be finitely generated, and hence $R$ is Noetherian.


\end{document}